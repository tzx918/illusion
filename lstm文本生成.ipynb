{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data10223  input\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: torch in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from torch) (1.16.4)\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (3.4.3)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from nltk) (1.11.0)\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: gensim in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (3.8.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from gensim) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim) (1.9.198)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from requests->smart-open>=1.7.0->gensim) (2018.8.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from requests->smart-open>=1.7.0->gensim) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.198 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.198)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.198->boto3->smart-open>=1.7.0->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.198->boto3->smart-open>=1.7.0->gensim) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10095813"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = zipfile.ZipFile('/home/aistudio/data/data10223/input.zip')\n",
    "for text in f.namelist():\n",
    "    f.extract(text,'data')\n",
    "#read text from path-data/input/\n",
    "#load train data\n",
    "raw_input=''\n",
    "for file in os.listdir('data/input/'):\n",
    "    if file.endswith('.txt'):\n",
    "        raw_input += open('data/input/'+file,errors='ignore').read()+'/n/n'\n",
    "raw_input =raw_input.lower()\n",
    "len(raw_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91008 [['\\ufeff', 'the', 'project', 'gutenberg', 'ebook', 'of', 'war', 'and', 'peace', ',', 'by', 'leo', 'tolstoy', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.'], ['you', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.org', 'title', ':', 'war', 'and', 'peace', 'author', ':', 'leo', 'tolstoy', 'translators', ':', 'louise', 'and', 'aylmer', 'maude', 'posting', 'date', ':', 'january', '10', ',', '2009', '[', 'ebook', '#', '2600', ']', 'last', 'updated', ':', 'july', '10', ',', '2016', 'language', ':', 'english', 'character', 'set', 'encoding', ':', 'utf-8', '***', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'war', 'and', 'peace', '***', 'an', 'anonymous', 'volunteer', ',', 'and', 'david', 'widger', 'war', 'and', 'peace', 'by', 'leo', 'tolstoy/tolstoi', 'contents', 'book', 'one', ':', '1805', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'chapter', 'xxiii', 'chapter', 'xxiv', 'chapter', 'xxv', 'chapter', 'xxvi', 'chapter', 'xxvii', 'chapter', 'xxviii', 'book', 'two', ':', '1805', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'book', 'three', ':', '1805', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'book', 'four', ':', '1806', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'book', 'five', ':', '1806', '-', '07', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'book', 'six', ':', '1808', '-', '10', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'chapter', 'xxiii', 'chapter', 'xxiv', 'chapter', 'xxv', 'chapter', 'xxvi', 'book', 'seven', ':', '1810', '-', '11', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'book', 'eight', ':', '1811', '-', '12', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'book', 'nine', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'chapter', 'xxiii', 'book', 'ten', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'chapter', 'xxiii', 'chapter', 'xxiv', 'chapter', 'xxv', 'chapter', 'xxvi', 'chapter', 'xxvii', 'chapter', 'xxviii', 'chapter', 'xxix', 'chapter', 'xxx', 'chapter', 'xxxi', 'chapter', 'xxxii', 'chapter', 'xxxiii', 'chapter', 'xxxiv', 'chapter', 'xxxv', 'chapter', 'xxxvi', 'chapter', 'xxxvii', 'chapter', 'xxxviii', 'chapter', 'xxxix', 'book', 'eleven', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'chapter', 'xxi', 'chapter', 'xxii', 'chapter', 'xxiii', 'chapter', 'xxiv', 'chapter', 'xxv', 'chapter', 'xxvi', 'chapter', 'xxvii', 'chapter', 'xxviii', 'chapter', 'xxix', 'chapter', 'xxx', 'chapter', 'xxxi', 'chapter', 'xxxii', 'chapter', 'xxxiii', 'chapter', 'xxxiv', 'book', 'twelve', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'book', 'thirteen', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'book', 'fourteen', ':', '1812', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'book', 'fifteen', ':', '1812', '-', '13', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'chapter', 'xvii', 'chapter', 'xviii', 'chapter', 'xix', 'chapter', 'xx', 'first', 'epilogue', ':', '1813', '-', '20', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'chapter', 'xiii', 'chapter', 'xiv', 'chapter', 'xv', 'chapter', 'xvi', 'second', 'epilogue', 'chapter', 'i', 'chapter', 'ii', 'chapter', 'iii', 'chapter', 'iv', 'chapter', 'v', 'chapter', 'vi', 'chapter', 'vii', 'chapter', 'viii', 'chapter', 'ix', 'chapter', 'x', 'chapter', 'xi', 'chapter', 'xii', 'book', 'one', ':', '1805', 'chapter', 'i', \"''\", 'well', ',', 'prince', ',', 'so', 'genoa', 'and', 'lucca', 'are', 'now', 'just', 'family', 'estates', 'of', 'the', 'buonapartes', '.'], ['but', 'i', 'warn', 'you', ',', 'if', 'you', 'do', \"n't\", 'tell', 'me', 'that', 'this', 'means', 'war', ',', 'if', 'you', 'still', 'try', 'to', 'defend', 'the', 'infamies', 'and', 'horrors', 'perpetrated', 'by', 'that', 'antichrist—i', 'really', 'believe', 'he', 'is', 'antichrist—i', 'will', 'have', 'nothing', 'more', 'to', 'do', 'with', 'you', 'and', 'you', 'are', 'no', 'longer', 'my', 'friend', ',', 'no', 'longer', 'my', \"'faithful\", 'slave', ',', \"'\", 'as', 'you', 'call', 'yourself', '!']]\n"
     ]
    }
   ],
   "source": [
    "#generate corpus\n",
    "# nltk.download('punkt')\n",
    "sentensor = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sents = sentensor.tokenize(raw_input)\n",
    "corpus =[]\n",
    "for sent in sents:\n",
    "    corpus.append(nltk.word_tokenize(sent))\n",
    "print(len(corpus),corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(corpus,size = 128,window =5,min_count=5,workers =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.08097128,  0.6936153 ,  0.00423524, -0.84916914, -0.13194412,\n",
       "       -0.5088186 , -1.045546  , -0.17689934,  1.0051972 , -1.4297673 ,\n",
       "       -0.3063496 ,  0.2347999 , -0.7072402 ,  0.03608833,  0.19963694,\n",
       "        1.289007  , -0.80805874,  0.8125486 , -0.8486462 , -0.62052965,\n",
       "        1.1633    ,  0.91593426,  0.49907967, -0.8294784 ,  1.1800019 ,\n",
       "       -1.2529138 ,  1.0564824 ,  0.9467202 , -0.6484134 ,  1.3103741 ,\n",
       "        0.06631478,  0.41897622, -0.6668992 ,  0.47560343,  1.1314778 ,\n",
       "       -0.8436495 ,  0.14436899,  0.22770965, -1.0136622 ,  0.5599207 ,\n",
       "       -0.11063586,  0.2165029 , -0.7754638 ,  0.5062332 , -1.5589148 ,\n",
       "        1.4143364 , -0.7103082 ,  0.35295254, -0.57782114,  0.7592008 ,\n",
       "        1.1699948 ,  1.3310163 ,  0.7833816 , -0.03093369,  0.9144621 ,\n",
       "        0.83177483,  0.22885782,  0.47413492, -0.7713383 , -0.15257275,\n",
       "        0.01211361, -0.39924744, -0.7323503 ,  0.11214639, -1.1527499 ,\n",
       "        0.2599746 , -0.6393489 ,  1.943616  ,  0.6476035 ,  1.386494  ,\n",
       "       -0.6259768 , -1.2158065 , -1.0848322 ,  0.18716355,  0.0419839 ,\n",
       "       -0.22312935,  0.84581447,  0.74102277,  0.88382167, -0.6390578 ,\n",
       "        0.5933198 , -0.8694518 , -0.45500112,  1.0861573 , -0.08987582,\n",
       "        0.28848743,  1.088814  , -0.6729868 ,  0.11854591,  0.09572852,\n",
       "        0.31585968, -0.06114981,  0.6250647 ,  0.6006715 ,  0.62316895,\n",
       "       -0.17629798,  0.63838905,  0.7083266 , -0.46818376,  0.13714387,\n",
       "        0.14507346, -0.69685125, -1.5431539 ,  0.68214196,  1.42521   ,\n",
       "       -0.33574507,  1.5697417 ,  0.10263275,  0.63700545,  0.9480116 ,\n",
       "       -1.1369845 ,  0.3914102 , -0.15760745, -0.9212869 ,  0.41529998,\n",
       "       -0.13211215, -0.0236487 ,  0.35648996,  0.6082609 ,  0.13273102,\n",
       "       -0.4782073 , -0.38903636,  0.48890027, -1.4434566 ,  0.03748017,\n",
       "       -0.9111545 ,  0.12799475,  1.4295031 ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2163932"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#short text to long text\n",
    "long_text = [word for i in corpus for word in i]\n",
    "len(long_text)\n",
    "# long_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111915"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#long text to word2vec matrics\n",
    "vocab = w2v_model.wv.vocab\n",
    "text_stream=[]\n",
    "for word in long_text:\n",
    "    if word in vocab:\n",
    "        text_stream.append(word)\n",
    "len(text_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.shape(text_matric)\n",
    "# \n",
    "# text_matric=[i.tolist() for i in text_matric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\r\n",
    "x = []\r\n",
    "y = []\r\n",
    "for i in range(0, len(text_stream) - seq_length):\r\n",
    "\r\n",
    "    given = text_stream[i:i + seq_length]\r\n",
    "    predict = text_stream[i + seq_length]\r\n",
    "    \r\n",
    "    x.append(np.array([w2v_model[word] for word in given]))\r\n",
    "    y.append(w2v_model[predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 128)\n",
      "(10000, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(x))\r\n",
    "print(np.shape(y))\r\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17282736 -0.19776772 -0.21184756 ...  0.2581108   0.10398757\n",
      "   0.43064287]\n",
      " [-1.6658446   0.21624139 -0.57488066 ...  0.04872503  0.6963573\n",
      "   0.7054776 ]\n",
      " [-2.3213308   0.47740346  1.8913143  ... -0.62702554 -0.39053968\n",
      "   1.5675222 ]\n",
      " ...\n",
      " [-1.0563048  -1.3735305   0.42858538 ...  0.00756986  1.0701725\n",
      "  -0.3103731 ]\n",
      " [-0.01519855 -0.08036461 -0.1489228  ...  0.72197044  0.22865202\n",
      "   1.2225527 ]\n",
      " [ 0.02623184  0.384041   -0.02404912 ... -0.27206993  0.01245334\n",
      "   1.2436208 ]]\n",
      "[ 0.68243     0.74709976  0.7283599   0.45779717 -0.36524865 -1.2341775\n",
      "  0.77812254  1.2016666  -0.29045656  1.0023327   0.78225726 -0.7116282\n",
      "  0.45909703  0.8668802   0.09425274  0.15508837 -0.6113337   0.4945426\n",
      "  0.90477127 -1.5546327  -1.0265106  -0.6149826  -1.0729828   0.81785154\n",
      "  1.2977047  -0.55070317  1.0714517  -0.3552713   0.10070386  0.02759533\n",
      " -0.07868946  0.2422542   0.38847056  1.4789011  -0.68261933 -0.78511477\n",
      " -1.3808337  -0.10038691 -0.560768    0.509973    0.8921577   0.54032284\n",
      "  0.2251198  -0.59588724 -0.27216557 -0.4946486   0.42023358  0.29778197\n",
      "  0.4576418   0.6967031   0.17116311  0.90052605  1.482178    0.5756586\n",
      "  0.7119291   0.21389861  0.5390942  -0.3317728  -0.11616784 -0.3849918\n",
      " -0.9438934  -0.09161456  0.6604547   0.07765712 -0.5147563   0.6345667\n",
      " -0.64290845  0.6305278  -0.2401895   1.2212492   0.48103982 -0.16785848\n",
      " -0.41656828  0.35614535  0.40671772  0.9238839   0.1212475   0.83293647\n",
      " -0.79839563 -0.34027898  0.17207591  0.14889474  0.4848049   0.44426867\n",
      "  0.29477602  0.2750632   0.1022864  -0.84149104  0.36245587  0.35447073\n",
      "  0.79531914 -0.6136029   0.05948411  0.37996832  0.3560148  -0.16668646\n",
      "  1.5071115   1.0940812  -0.1596982   0.81136733 -0.0778317   0.1597355\n",
      "  0.49243525 -0.17731503 -0.40809295  1.2748128   0.13991119  0.83263594\n",
      "  0.6502823   0.7164943   0.24892905 -0.7982912   1.0179479  -0.15639539\n",
      "  0.17652887  0.41744772  0.23971634  0.19589534 -0.07630613 -0.18722837\n",
      " -1.9054321   0.53811777  0.35810262 -0.05709017  0.7026964   0.41405284\n",
      " -0.1371129   0.1656327 ]\n"
     ]
    }
   ],
   "source": [
    "# print(len(x))\r\n",
    "# print(len(y))\r\n",
    "print(x[-1])\r\n",
    "# print(len(x[12][0]))\r\n",
    "print(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.utils.data.dataloader as dataloader\r\n",
    "import torch.optim as optim\r\n",
    "import torch.autograd as autograd\r\n",
    "# import torchtext.vocab as torchvocab\r\n",
    "from torch.autograd import Variable\r\n",
    "# import tqdm\r\n",
    "import os\r\n",
    "import os\r\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\r\n",
    "import time\r\n",
    "import re\r\n",
    "import pandas as pd\r\n",
    "import string\r\n",
    "import gensim\r\n",
    "import time\r\n",
    "import random\r\n",
    "# import snowballstemmer\r\n",
    "import collections\r\n",
    "from collections import Counter\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from itertools import chain\r\n",
    "from sklearn.metrics import accuracy_score\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\r\n",
    "    def __init__(self, embed_size, num_hiddens, num_layers,\r\n",
    "                 bidirectional, weight, labels, use_gpu, **kwargs):\r\n",
    "        super(SentimentNet, self).__init__(**kwargs)\r\n",
    "        self.num_hiddens = num_hiddens\r\n",
    "        self.num_layers = num_layers\r\n",
    "        self.use_gpu = use_gpu\r\n",
    "        self.bidirectional = bidirectional\r\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=self.num_hiddens,\r\n",
    "                               num_layers=num_layers, bidirectional=self.bidirectional,\r\n",
    "                               dropout=0)\r\n",
    "\r\n",
    "        self.decoder = nn.Linear(num_hiddens * 2, labels)\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        states, hidden = self.encoder(x)\r\n",
    "        outputs = self.decoder(states[:,-1,:])\r\n",
    "        return outputs\r\n",
    "\r\n",
    "def train(x,y):\r\n",
    "\r\n",
    "    train_features = torch.tensor(x)\r\n",
    "    train_labels=torch.tensor(y)\r\n",
    "    \r\n",
    "    train_set = torch.utils.data.TensorDataset(train_features, train_labels)\r\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\r\n",
    "                                             shuffle=True)\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "    start = time.time()\r\n",
    "    train_loss, test_losses = 0, 0\r\n",
    "    train_acc, test_acc = 0, 0\r\n",
    "    n, m = 0, 0\r\n",
    "        for feature, label in train_iter:\r\n",
    "            n += 1\r\n",
    "            net.zero_grad()\r\n",
    "            feature = Variable(feature)\r\n",
    "            label = Variable(label)\r\n",
    "            score = net(feature)\r\n",
    "            loss = loss_function(score, label)\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            train_loss += loss\r\n",
    "            # print(train_loss)\r\n",
    "        end = time.time()\r\n",
    "        runtime = end - start\r\n",
    "        print('epoch: %d, train loss: %.4f, time: %.2f' %\r\n",
    "              (epoch, train_loss.data / n, runtime))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\r\n",
    "embed_size = 128\r\n",
    "num_hiddens = 128\r\n",
    "num_layers = 2\r\n",
    "bidirectional = True\r\n",
    "batch_size = 2\r\n",
    "labels = 128\r\n",
    "lr = 0.8\r\n",
    "device = torch.device('cuda:0')\r\n",
    "use_gpu = False\r\n",
    "vocab_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "net = SentimentNet(embed_size=embed_size,\r\n",
    "                   num_hiddens=num_hiddens, num_layers=num_layers,\r\n",
    "                   bidirectional=bidirectional, weight=weight,\r\n",
    "                   labels=labels, use_gpu=use_gpu)\r\n",
    "x = x[:10000]\r\n",
    "y = y[:10000]     \r\n",
    "loss_function = nn.MSELoss() \r\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.6526, time: 82.80\n",
      "epoch: 1, train loss: 0.6107, time: 83.99\n",
      "epoch: 2, train loss: 0.6017, time: 84.10\n",
      "epoch: 3, train loss: 0.5956, time: 81.69\n",
      "epoch: 4, train loss: 0.5915, time: 82.92\n"
     ]
    }
   ],
   "source": [
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = 'Language Models allow us to measure how likely a sentence is, which is an important for Machine'\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-aab42b932e9a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-aab42b932e9a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    nn.Linear(num_hiddens * 4, labels)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    self.encoder = nn.LSTM(input_size=embed_size, hidden_size=self.num_hiddens,\n",
    "                               num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               dropout=0)\n",
    "    nn.Linear(num_hiddens * 4, labels)                         \n",
    "    )\n",
    "    \n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr = 0.2)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "batch_data  = Data.TensorDataSet(data_tensor=x,targe_tensor=y)\n",
    "loader = DataLoader(\n",
    "    dataset=batch_data,\n",
    "    bath_size=bath_size,\n",
    "    shuffle=True,\n",
    "    num_works = 2)\n",
    "for epoch in range(epochs):\n",
    "    for step,(x,y) in enumerate(loader):\n",
    "        x_input =torch.autograd.Variable(torch.from_numpy(X))\n",
    "        y_input =torch.autograd.Variable(torch.from_numpy(y))\n",
    "        y_pre = Lstm(x_input)\n",
    "        loss = loss_fun(y_pre,y_input)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/7c/fb/7b2c5b3e85ad335b53ca67deb2ef4af574dc0a8759f43b7f45e15005e449/tensorflow-1.14.0-cp35-cp35m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.2MB 382kB/s eta 0:00:01    92% |█████████████████████████████▌  | 100.7MB 79.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorflow) (0.32.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 15.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 28.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 27.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[33m  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))': /pypi/web/simple/absl-py/\u001b[0m\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 36.5MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorflow) (3.8.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/7e/8e/9e446349fc449951ecf3768070483ea88e76725cdd5bbddb9bc50f6948d4/grpcio-1.22.0-cp35-cp35m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 16.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 21.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 37.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.4)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl (575kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 30.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 37.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Building wheels for collected packages: gast, wrapt, absl-py\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/aistudio/.cache/pip/wheels/64/c1/4a/6a238079b7e5a1c2c479001cf50f9f18655b3bb04bb9d32619\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/aistudio/.cache/pip/wheels/2b/41/10/f47b78a44fd5bb824ea9d347863166debc2b0b5a6b28563d76\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/aistudio/.cache/pip/wheels/cc/27/b8/80769636fbf30d2fddba4c6e149163c0a319ba2dfc73f6e660\n",
      "Successfully built gast wrapt absl-py\n",
      "Installing collected packages: grpcio, setuptools, absl-py, markdown, tensorboard, keras-preprocessing, gast, keras-applications, wrapt, google-pasta, tensorflow-estimator, astor, tensorflow\n",
      "  Found existing installation: setuptools 40.4.3\n",
      "    Uninstalling setuptools-40.4.3:\n",
      "      Successfully uninstalled setuptools-40.4.3\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 setuptools-41.0.1 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 wrapt-1.11.2\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 22.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (1.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages (from keras) (1.0.8)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 00:28:16.352485 139821890770688 deprecation_wrapper.py:119] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, dropout=0.2, recurrent_dropout=0.2, input_shape=(10, 128))`\n",
      "  \n",
      "W0731 00:28:16.371665 139821890770688 deprecation_wrapper.py:119] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0731 00:28:16.375435 139821890770688 deprecation_wrapper.py:119] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0731 00:28:17.055562 139821890770688 deprecation_wrapper.py:119] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0731 00:28:17.064527 139821890770688 deprecation.py:506] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0731 00:28:17.947501 139821890770688 deprecation_wrapper.py:119] From /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\r\n",
    "model.add(LSTM(256, dropout_W=0.2, dropout_U=0.2, input_shape=(seq_length, 128)))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "model.add(Dense(128, activation='sigmoid'))\r\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-177d54e30fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array_repr_implementation\u001b[0;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0;32m-> 1419\u001b[0;31m                            ', ', prefix, suffix=suffix)\n\u001b[0m\u001b[1;32m   1420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[], shape=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, **kwarg)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;31m# find the right formatting function for the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0mformat_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_format_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;31m# skip over \"[\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_get_format_function\u001b[0;34m(data, **options)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longfloat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclongfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;34m'int'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntegerFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;34m'float'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mFloatingFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;34m'longfloat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mFloatingFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, precision, floatmode, suppress_small, sign, **kwarg)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlarge_exponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mfillFormat\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    914\u001b[0m                                        sign=self.sign == '+')\n\u001b[1;32m    915\u001b[0m                     for x in finite_vals)\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mint_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1.13'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mint_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m                                        sign=self.sign == '+')\n\u001b[1;32m    915\u001b[0m                     for x in finite_vals)\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mint_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1.13'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mint_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                        \u001b[0munique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                        sign=self.sign == '+')\n\u001b[0;32m--> 915\u001b[0;31m                     for x in finite_vals)\n\u001b[0m\u001b[1;32m    916\u001b[0m             \u001b[0mint_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1.13'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x, y, epochs=2, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x):\r\n",
    "    train_features = torch.tensor(x)\r\n",
    "    # train_set = torch.utils.data.TensorDataset(train_features)\r\n",
    "    # train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\r\n",
    "    #                                          shuffle=True)\r\n",
    "    # for feature in train_iter:\r\n",
    "    feature = Variable(train_features)\r\n",
    "    score = net(feature)\r\n",
    "    score=score.detach().numpy()\r\n",
    "    # print(np.shape(score),score)\r\n",
    "    return score\r\n",
    "def predict_next(input_array):\r\n",
    "    x = np.reshape(input_array, (-1,seq_length,128))\r\n",
    "    y = test(x)\r\n",
    "    return y\r\n",
    "\r\n",
    "def string_to_index(raw_input):\r\n",
    "    raw_input = raw_input.lower()\r\n",
    "    input_stream = nltk.word_tokenize(raw_input)\r\n",
    "    res = []\r\n",
    "    for word in input_stream[(len(input_stream)-seq_length):]:\r\n",
    "        res.append(w2v_model[word])\r\n",
    "    return res\r\n",
    "\r\n",
    "def y_to_word(y):\r\n",
    "    word = w2v_model.most_similar(positive=y, topn=1)\r\n",
    "    return word\r\n",
    "def generate_article(init, rounds=30):\r\n",
    "    in_string = init.lower()\r\n",
    "    for i in range(rounds):\r\n",
    "        n = y_to_word(predict_next(string_to_index(in_string)))\r\n",
    "        in_string += ' ' + n[0][0]\r\n",
    "    return in_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = 'Language Models allow us to measure how likely a sentence is, which is an important for Machine'\r\n",
    "article = generate_article(init)\r\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.5.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
